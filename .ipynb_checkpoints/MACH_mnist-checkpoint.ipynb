{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1007 17:19:10.104164 4628436416 __init__.py:690] \n",
      "\n",
      "  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n",
      "\n",
      "  Please upgrade your code to TensorFlow 2.0:\n",
      "    * https://www.tensorflow.org/beta/guide/migration_guide\n",
      "\n",
      "  Or install the latest stable TensorFlow 1.X release:\n",
      "    * `pip install -U \"tensorflow==1.*\"`\n",
      "\n",
      "  Otherwise your code may be broken by the change.\n",
      "\n",
      "  \n",
      "W1007 17:19:11.436979 4628436416 deprecation.py:323] From <ipython-input-1-339a9f4bb712>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W1007 17:19:11.437775 4628436416 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W1007 17:19:11.439220 4628436416 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W1007 17:19:11.619971 4628436416 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W1007 17:19:11.623149 4628436416 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1007 17:19:11.662976 4628436416 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.n_input = 784  # input layer (28x28 pixels)\n",
    "        self.n_hidden1 = 512  # 1st hidden layer\n",
    "        self.n_hidden2 = 256  # 2nd hidden layer\n",
    "        self.n_hidden3 = 128  # 3rd hidden layer\n",
    "        self.n_output = 10  # output layer (0-9 digits)\n",
    "        self.n_model_inputs = self.n_input + self.n_hidden3  # input layer (28x28 pixels)\n",
    "\n",
    "        self.learning_rate = 1e-4\n",
    "        self.learn_iterations = 1000\n",
    "        self.batch_size = 200\n",
    "        self.dropout = 0.5\n",
    "\n",
    "class Mach:\n",
    "\n",
    "    def __init__(self, config, mnist):\n",
    "        self.c = config\n",
    "        self.mnist = mnist\n",
    "        self.n_train = self.mnist.train.num_examples  # 55,000\n",
    "        self.n_validation = self.mnist.validation.num_examples  # 5000\n",
    "        self.n_test = self.mnist.test.num_examples  # 10,000\n",
    "\n",
    "        self.graph = tf.Graph()\n",
    "        self.session = tf.Session(graph=self.graph)\n",
    "        with self.graph.as_default():\n",
    "            self.input_fn()\n",
    "            self.model_fn()\n",
    "            self.loss_fn()\n",
    "            init = tf.global_variables_initializer()\n",
    "        self.session.run(init)\n",
    "        \n",
    "        self.child = None\n",
    "        \n",
    "    def input_fn(self):\n",
    "        # Placeholders.\n",
    "        self.X = tf.placeholder(tf.float32, [None, self.c.n_input])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, self.c.n_output])\n",
    "        self.C = tf.placeholder(tf.float32, [None, self.c.n_hidden3])\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "            \n",
    "    def loss_fn(self):\n",
    "        self.cross_entropy = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.Y, logits=self.logits))\n",
    "        self.train_step = tf.train.AdamOptimizer(self.c.learning_rate).minimize(self.cross_entropy)\n",
    "        self.correct_pred = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
    "    \n",
    "    def model_fn(self):\n",
    "        self.model_inputs = tf.concat([self.X, self.C], axis=1)\n",
    "        \n",
    "        weights = {\n",
    "            'w1': tf.Variable(tf.truncated_normal([self.c.n_model_inputs, self.c.n_hidden1], stddev=0.1)),\n",
    "            'w2': tf.Variable(tf.truncated_normal([self.c.n_hidden1, self.c.n_hidden2], stddev=0.1)),\n",
    "            'w3': tf.Variable(tf.truncated_normal([self.c.n_hidden2, self.c.n_hidden3], stddev=0.1)),\n",
    "            'out': tf.Variable(tf.truncated_normal([self.c.n_hidden3, self.c.n_output], stddev=0.1)),\n",
    "        }\n",
    "\n",
    "        biases = {\n",
    "            'b1': tf.Variable(tf.constant(0.1, shape=[self.c.n_hidden1])),\n",
    "            'b2': tf.Variable(tf.constant(0.1, shape=[self.c.n_hidden2])),\n",
    "            'b3': tf.Variable(tf.constant(0.1, shape=[self.c.n_hidden3])),\n",
    "            'out': tf.Variable(tf.constant(0.1, shape=[self.c.n_output]))\n",
    "        }\n",
    "\n",
    "        self.layer_1 = tf.add(tf.matmul(self.model_inputs, weights['w1']), biases['b1'])\n",
    "        self.layer_2 = tf.add(tf.matmul(self.layer_1, weights['w2']), biases['b2'])\n",
    "        self.layer_3 = tf.add(tf.matmul(self.layer_2, weights['w3']), biases['b3'])\n",
    "        layer_drop = tf.nn.dropout(self.layer_3, rate = (1 - self.keep_prob))\n",
    "        self.logits = tf.matmul(self.layer_3, weights['out']) + biases['out']\n",
    "        \n",
    "    def Child(self, batch):\n",
    "        if self.child == None:\n",
    "            return numpy.zeros((numpy.shape(batch)[0], self.c.n_hidden3))\n",
    "        else:\n",
    "            return self.child.Spike(batch)\n",
    "        \n",
    "    def Spike(self, batch):\n",
    "        feeds={self.X: batch, self.C: self.Child(batch), self.keep_prob: 1.0}\n",
    "        return self.session.run([self.layer_3], feed_dict=feeds)[0]\n",
    "        \n",
    "    def Train(self):\n",
    "        # train on mini batches\n",
    "        for i in range(self.c.learn_iterations):    \n",
    "            batch_x, batch_y = self.mnist.train.next_batch(self.c.batch_size)\n",
    "            feeds={self.X: batch_x, self.Y: batch_y, self.C: self.Child(batch_x), self.keep_prob: self.c.dropout}\n",
    "            self.session.run(self.train_step, feed_dict=feeds)\n",
    "\n",
    "#             # print loss and accuracy (per minibatch)\n",
    "#             if i % 100 == 0:\n",
    "#                 fetches = [self.cross_entropy, self.accuracy]\n",
    "#                 feeds = {self.X: batch_x, self.Y: batch_y, self.C: self.Child(batch_x), self.keep_prob: 1.0}\n",
    "#                 minibatch_loss, minibatch_accuracy = self.session.run(fetches,feeds)    \n",
    "#                 print(\n",
    "#                     \"Iteration\",\n",
    "#                     str(i),\n",
    "#                     \"\\t| Loss =\",\n",
    "#                     str(minibatch_loss),\n",
    "#                     \"\\t| Accuracy =\",\n",
    "#                     str(minibatch_accuracy)\n",
    "#                     )\n",
    "                \n",
    "    def Test(self):\n",
    "        feed_dict = {\n",
    "                self.X: self.mnist.test.images, \n",
    "                self.Y: self.mnist.test.labels, \n",
    "                self.C: self.Child(self.mnist.test.images), \n",
    "                self.keep_prob: 1.0\n",
    "        }\n",
    "        test_accuracy = self.session.run(self.accuracy, feed_dict=feed_dict)\n",
    "        print(\"\\nAccuracy on test set:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Config()\n",
    "m = Mach(c, mnist)\n",
    "\n",
    "c2 = Config()\n",
    "m2 = Mach(c2, mnist)\n",
    "\n",
    "m.child = m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train m2\n",
      "Iteration 0 \t| Loss = 4.183218 \t| Accuracy = 0.115\n",
      "Iteration 100 \t| Loss = 0.50710016 \t| Accuracy = 0.835\n",
      "Iteration 200 \t| Loss = 0.34050804 \t| Accuracy = 0.895\n",
      "Iteration 300 \t| Loss = 0.40576214 \t| Accuracy = 0.875\n",
      "Iteration 400 \t| Loss = 0.42428926 \t| Accuracy = 0.88\n",
      "Iteration 500 \t| Loss = 0.4117105 \t| Accuracy = 0.9\n",
      "Iteration 600 \t| Loss = 0.2292279 \t| Accuracy = 0.94\n",
      "Iteration 700 \t| Loss = 0.23595196 \t| Accuracy = 0.92\n",
      "Iteration 800 \t| Loss = 0.23535484 \t| Accuracy = 0.94\n",
      "Iteration 900 \t| Loss = 0.2830325 \t| Accuracy = 0.91\n",
      "Train m1\n",
      "Iteration 0 \t| Loss = 10.434746 \t| Accuracy = 0.06\n",
      "Iteration 100 \t| Loss = 0.4295957 \t| Accuracy = 0.885\n",
      "Iteration 200 \t| Loss = 0.3361736 \t| Accuracy = 0.875\n",
      "Iteration 300 \t| Loss = 0.18388024 \t| Accuracy = 0.93\n",
      "Iteration 400 \t| Loss = 0.32934842 \t| Accuracy = 0.885\n",
      "Iteration 500 \t| Loss = 0.26771992 \t| Accuracy = 0.91\n",
      "Iteration 600 \t| Loss = 0.4361591 \t| Accuracy = 0.89\n",
      "Iteration 700 \t| Loss = 0.24232748 \t| Accuracy = 0.925\n",
      "Iteration 800 \t| Loss = 0.3361958 \t| Accuracy = 0.91\n",
      "Iteration 900 \t| Loss = 0.32734582 \t| Accuracy = 0.9\n",
      "Test m2\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataSet' object has no attribute 'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-9680808b3586>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Test m2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'Test m1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-9f703b60da86>\u001b[0m in \u001b[0;36mTest\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         }\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataSet' object has no attribute 'image'"
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    print ('Train m2')\n",
    "    m2.Train()\n",
    "    print ('Train m1')\n",
    "    m.Train()\n",
    "    print ('Test m2')\n",
    "    m2.Test()\n",
    "    print ('Test m1')\n",
    "    m.Test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 \t| Loss = 2.8958972 \t| Accuracy = 0.14\n",
      "Iteration 100 \t| Loss = 0.46182445 \t| Accuracy = 0.845\n",
      "Iteration 200 \t| Loss = 0.43906534 \t| Accuracy = 0.89\n",
      "Iteration 300 \t| Loss = 0.38357255 \t| Accuracy = 0.89\n",
      "Iteration 400 \t| Loss = 0.29044545 \t| Accuracy = 0.9\n",
      "Iteration 500 \t| Loss = 0.2975753 \t| Accuracy = 0.91\n",
      "Iteration 600 \t| Loss = 0.2667142 \t| Accuracy = 0.92\n",
      "Iteration 700 \t| Loss = 0.28674346 \t| Accuracy = 0.93\n",
      "Iteration 800 \t| Loss = 0.34489277 \t| Accuracy = 0.87\n",
      "Iteration 900 \t| Loss = 0.2385223 \t| Accuracy = 0.92\n"
     ]
    }
   ],
   "source": [
    "m2.Train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
