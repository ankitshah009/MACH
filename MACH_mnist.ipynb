{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1007 17:19:10.104164 4628436416 __init__.py:690] \n",
      "\n",
      "  TensorFlow's `tf-nightly` package will soon be updated to TensorFlow 2.0.\n",
      "\n",
      "  Please upgrade your code to TensorFlow 2.0:\n",
      "    * https://www.tensorflow.org/beta/guide/migration_guide\n",
      "\n",
      "  Or install the latest stable TensorFlow 1.X release:\n",
      "    * `pip install -U \"tensorflow==1.*\"`\n",
      "\n",
      "  Otherwise your code may be broken by the change.\n",
      "\n",
      "  \n",
      "W1007 17:19:11.436979 4628436416 deprecation.py:323] From <ipython-input-1-339a9f4bb712>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W1007 17:19:11.437775 4628436416 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W1007 17:19:11.439220 4628436416 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W1007 17:19:11.619971 4628436416 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W1007 17:19:11.623149 4628436416 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1007 17:19:11.662976 4628436416 deprecation.py:323] From /usr/local/lib/python3.7/site-packages/tensorflow_core/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)  #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self):\n",
    "        self.n_input = 784  # input layer (28x28 pixels)\n",
    "        self.n_hidden1 = 512  # 1st hidden layer\n",
    "        self.n_hidden2 = 256  # 2nd hidden layer\n",
    "        self.n_hidden3 = 128  # 3rd hidden layer\n",
    "        self.n_output = 10  # output layer (0-9 digits)\n",
    "        self.n_model_inputs = self.n_input + self.n_hidden3  # input layer (28x28 pixels)\n",
    "\n",
    "        self.learning_rate = 1e-4\n",
    "        self.learn_iterations = 1000\n",
    "        self.batch_size = 200\n",
    "        self.dropout = 0.5\n",
    "\n",
    "class Mach:\n",
    "\n",
    "    def __init__(self, config, mnist):\n",
    "        self.c = config\n",
    "        self.mnist = mnist\n",
    "        self.n_train = self.mnist.train.num_examples  # 55,000\n",
    "        self.n_validation = self.mnist.validation.num_examples  # 5000\n",
    "        self.n_test = self.mnist.test.num_examples  # 10,000\n",
    "\n",
    "        self.graph = tf.Graph()\n",
    "        self.session = tf.Session(graph=self.graph)\n",
    "        with self.graph.as_default():\n",
    "            self.input_fn()\n",
    "            self.model_fn()\n",
    "            self.loss_fn()\n",
    "            init = tf.global_variables_initializer()\n",
    "        self.session.run(init)\n",
    "        \n",
    "        self.child = None\n",
    "        \n",
    "    def input_fn(self):\n",
    "        # Placeholders.\n",
    "        self.X = tf.placeholder(tf.float32, [None, self.c.n_input])\n",
    "        self.Y = tf.placeholder(tf.float32, [None, self.c.n_output])\n",
    "        self.C = tf.placeholder(tf.float32, [None, self.c.n_hidden3])\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "            \n",
    "    def loss_fn(self):\n",
    "        self.cross_entropy = tf.reduce_mean( tf.nn.softmax_cross_entropy_with_logits_v2(labels=self.Y, logits=self.logits))\n",
    "        self.train_step = tf.train.AdamOptimizer(self.c.learning_rate).minimize(self.cross_entropy)\n",
    "        self.correct_pred = tf.equal(tf.argmax(self.logits, 1), tf.argmax(self.Y, 1))\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(self.correct_pred, tf.float32))\n",
    "    \n",
    "    def model_fn(self):\n",
    "        self.model_inputs = tf.concat([self.X, self.C], axis=1)\n",
    "        \n",
    "        weights = {\n",
    "            'w1': tf.Variable(tf.truncated_normal([self.c.n_model_inputs, self.c.n_hidden1], stddev=0.1)),\n",
    "            'w2': tf.Variable(tf.truncated_normal([self.c.n_hidden1, self.c.n_hidden2], stddev=0.1)),\n",
    "            'w3': tf.Variable(tf.truncated_normal([self.c.n_hidden2, self.c.n_hidden3], stddev=0.1)),\n",
    "            'out': tf.Variable(tf.truncated_normal([self.c.n_hidden3, self.c.n_output], stddev=0.1)),\n",
    "        }\n",
    "\n",
    "        biases = {\n",
    "            'b1': tf.Variable(tf.constant(0.1, shape=[self.c.n_hidden1])),\n",
    "            'b2': tf.Variable(tf.constant(0.1, shape=[self.c.n_hidden2])),\n",
    "            'b3': tf.Variable(tf.constant(0.1, shape=[self.c.n_hidden3])),\n",
    "            'out': tf.Variable(tf.constant(0.1, shape=[self.c.n_output]))\n",
    "        }\n",
    "\n",
    "        self.layer_1 = tf.add(tf.matmul(self.model_inputs, weights['w1']), biases['b1'])\n",
    "        self.layer_2 = tf.add(tf.matmul(self.layer_1, weights['w2']), biases['b2'])\n",
    "        self.layer_3 = tf.add(tf.matmul(self.layer_2, weights['w3']), biases['b3'])\n",
    "        layer_drop = tf.nn.dropout(self.layer_3, rate = (1 - self.keep_prob))\n",
    "        self.logits = tf.matmul(self.layer_3, weights['out']) + biases['out']\n",
    "        \n",
    "    def Child(self, batch):\n",
    "        if self.child == None:\n",
    "            return numpy.zeros((numpy.shape(batch)[0], self.c.n_hidden3))\n",
    "        else:\n",
    "            return self.child.Spike(batch)\n",
    "        \n",
    "    def Spike(self, batch):\n",
    "        feeds={self.X: batch, self.C: self.Child(batch), self.keep_prob: 1.0}\n",
    "        return self.session.run([self.layer_3], feed_dict=feeds)[0]\n",
    "        \n",
    "    def Train(self):\n",
    "        # train on mini batches\n",
    "        for i in range(self.c.learn_iterations):    \n",
    "            batch_x, batch_y = self.mnist.train.next_batch(self.c.batch_size)\n",
    "            feeds={self.X: batch_x, self.Y: batch_y, self.C: self.Child(batch_x), self.keep_prob: self.c.dropout}\n",
    "            self.session.run(self.train_step, feed_dict=feeds)\n",
    "\n",
    "#             # print loss and accuracy (per minibatch)\n",
    "#             if i % 100 == 0:\n",
    "#                 fetches = [self.cross_entropy, self.accuracy]\n",
    "#                 feeds = {self.X: batch_x, self.Y: batch_y, self.C: self.Child(batch_x), self.keep_prob: 1.0}\n",
    "#                 minibatch_loss, minibatch_accuracy = self.session.run(fetches,feeds)    \n",
    "#                 print(\n",
    "#                     \"Iteration\",\n",
    "#                     str(i),\n",
    "#                     \"\\t| Loss =\",\n",
    "#                     str(minibatch_loss),\n",
    "#                     \"\\t| Accuracy =\",\n",
    "#                     str(minibatch_accuracy)\n",
    "#                     )\n",
    "                \n",
    "    def Test(self):\n",
    "        feed_dict = {\n",
    "                self.X: self.mnist.test.images, \n",
    "                self.Y: self.mnist.test.labels, \n",
    "                self.C: self.Child(self.mnist.test.images), \n",
    "                self.keep_prob: 1.0\n",
    "        }\n",
    "        test_accuracy = self.session.run(self.accuracy, feed_dict=feed_dict)\n",
    "        print(\"\\nAccuracy on test set:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Config()\n",
    "m = Mach(c, mnist)\n",
    "\n",
    "c2 = Config()\n",
    "m2 = Mach(c2, mnist)\n",
    "\n",
    "m.child = m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy on test set: 0.9194\n",
      "\n",
      "Accuracy on test set: 0.9234\n",
      "\n",
      "Accuracy on test set: 0.9229\n",
      "\n",
      "Accuracy on test set: 0.9215\n",
      "\n",
      "Accuracy on test set: 0.9231\n",
      "\n",
      "Accuracy on test set: 0.9204\n",
      "\n",
      "Accuracy on test set: 0.9208\n",
      "\n",
      "Accuracy on test set: 0.9215\n",
      "\n",
      "Accuracy on test set: 0.9205\n",
      "\n",
      "Accuracy on test set: 0.9217\n",
      "\n",
      "Accuracy on test set: 0.9207\n",
      "\n",
      "Accuracy on test set: 0.922\n",
      "\n",
      "Accuracy on test set: 0.9194\n",
      "\n",
      "Accuracy on test set: 0.9209\n",
      "\n",
      "Accuracy on test set: 0.9213\n",
      "\n",
      "Accuracy on test set: 0.9189\n",
      "\n",
      "Accuracy on test set: 0.9192\n",
      "\n",
      "Accuracy on test set: 0.9217\n",
      "\n",
      "Accuracy on test set: 0.9209\n",
      "\n",
      "Accuracy on test set: 0.9211\n",
      "\n",
      "Accuracy on test set: 0.9211\n",
      "\n",
      "Accuracy on test set: 0.9217\n",
      "\n",
      "Accuracy on test set: 0.9205\n",
      "\n",
      "Accuracy on test set: 0.9196\n",
      "\n",
      "Accuracy on test set: 0.9214\n",
      "\n",
      "Accuracy on test set: 0.9197\n",
      "\n",
      "Accuracy on test set: 0.9224\n",
      "\n",
      "Accuracy on test set: 0.9207\n",
      "\n",
      "Accuracy on test set: 0.9202\n",
      "\n",
      "Accuracy on test set: 0.9209\n",
      "\n",
      "Accuracy on test set: 0.9212\n",
      "\n",
      "Accuracy on test set: 0.9206\n",
      "\n",
      "Accuracy on test set: 0.9217\n",
      "\n",
      "Accuracy on test set: 0.921\n",
      "\n",
      "Accuracy on test set: 0.9196\n",
      "\n",
      "Accuracy on test set: 0.9217\n",
      "\n",
      "Accuracy on test set: 0.92\n",
      "\n",
      "Accuracy on test set: 0.9234\n",
      "\n",
      "Accuracy on test set: 0.9216\n",
      "\n",
      "Accuracy on test set: 0.9204\n",
      "\n",
      "Accuracy on test set: 0.9212\n",
      "\n",
      "Accuracy on test set: 0.9213\n",
      "\n",
      "Accuracy on test set: 0.9206\n",
      "\n",
      "Accuracy on test set: 0.9198\n",
      "\n",
      "Accuracy on test set: 0.9215\n",
      "\n",
      "Accuracy on test set: 0.9188\n",
      "\n",
      "Accuracy on test set: 0.9203\n",
      "\n",
      "Accuracy on test set: 0.92\n",
      "\n",
      "Accuracy on test set: 0.9216\n",
      "\n",
      "Accuracy on test set: 0.9209\n",
      "\n",
      "Accuracy on test set: 0.9209\n",
      "\n",
      "Accuracy on test set: 0.9209\n",
      "\n",
      "Accuracy on test set: 0.9221\n",
      "\n",
      "Accuracy on test set: 0.9202\n",
      "\n",
      "Accuracy on test set: 0.9214\n",
      "\n",
      "Accuracy on test set: 0.9215\n",
      "\n",
      "Accuracy on test set: 0.9195\n",
      "\n",
      "Accuracy on test set: 0.9217\n",
      "\n",
      "Accuracy on test set: 0.9206\n",
      "\n",
      "Accuracy on test set: 0.9206\n",
      "\n",
      "Accuracy on test set: 0.9215\n",
      "\n",
      "Accuracy on test set: 0.9217\n",
      "\n",
      "Accuracy on test set: 0.919\n",
      "\n",
      "Accuracy on test set: 0.9211\n",
      "\n",
      "Accuracy on test set: 0.9207\n",
      "\n",
      "Accuracy on test set: 0.921\n",
      "\n",
      "Accuracy on test set: 0.9202\n",
      "\n",
      "Accuracy on test set: 0.9206\n",
      "\n",
      "Accuracy on test set: 0.9209\n",
      "\n",
      "Accuracy on test set: 0.9216\n",
      "\n",
      "Accuracy on test set: 0.9203\n",
      "\n",
      "Accuracy on test set: 0.9212\n",
      "\n",
      "Accuracy on test set: 0.9205\n",
      "\n",
      "Accuracy on test set: 0.9201\n",
      "\n",
      "Accuracy on test set: 0.9213\n",
      "\n",
      "Accuracy on test set: 0.9213\n",
      "\n",
      "Accuracy on test set: 0.9197\n",
      "\n",
      "Accuracy on test set: 0.9206\n",
      "\n",
      "Accuracy on test set: 0.9202\n",
      "\n",
      "Accuracy on test set: 0.9201\n",
      "\n",
      "Accuracy on test set: 0.92\n",
      "\n",
      "Accuracy on test set: 0.921\n",
      "\n",
      "Accuracy on test set: 0.9206\n",
      "\n",
      "Accuracy on test set: 0.9189\n",
      "\n",
      "Accuracy on test set: 0.9203\n",
      "\n",
      "Accuracy on test set: 0.9199\n",
      "\n",
      "Accuracy on test set: 0.922\n",
      "\n",
      "Accuracy on test set: 0.9223\n",
      "\n",
      "Accuracy on test set: 0.9207\n",
      "\n",
      "Accuracy on test set: 0.9208\n",
      "\n",
      "Accuracy on test set: 0.9206\n",
      "\n",
      "Accuracy on test set: 0.9211\n",
      "\n",
      "Accuracy on test set: 0.9203\n",
      "\n",
      "Accuracy on test set: 0.9203\n",
      "\n",
      "Accuracy on test set: 0.9189\n",
      "\n",
      "Accuracy on test set: 0.922\n",
      "\n",
      "Accuracy on test set: 0.92\n",
      "\n",
      "Accuracy on test set: 0.9198\n",
      "\n",
      "Accuracy on test set: 0.921\n",
      "\n",
      "Accuracy on test set: 0.9202\n",
      "\n",
      "Accuracy on test set: 0.9197\n",
      "\n",
      "Accuracy on test set: 0.9202\n",
      "\n",
      "Accuracy on test set: 0.9204\n",
      "\n",
      "Accuracy on test set: 0.9205\n",
      "\n",
      "Accuracy on test set: 0.9209\n",
      "\n",
      "Accuracy on test set: 0.9202\n",
      "\n",
      "Accuracy on test set: 0.9205\n",
      "\n",
      "Accuracy on test set: 0.9201\n",
      "\n",
      "Accuracy on test set: 0.9193\n",
      "\n",
      "Accuracy on test set: 0.9196\n",
      "\n",
      "Accuracy on test set: 0.9203\n",
      "\n",
      "Accuracy on test set: 0.9208\n",
      "\n",
      "Accuracy on test set: 0.9209\n",
      "\n",
      "Accuracy on test set: 0.9203\n",
      "\n",
      "Accuracy on test set: 0.92\n",
      "\n",
      "Accuracy on test set: 0.9186\n",
      "\n",
      "Accuracy on test set: 0.9198\n",
      "\n",
      "Accuracy on test set: 0.9206\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-c18b2c6be65b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mm2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-7825f6279fce>\u001b[0m in \u001b[0;36mTrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mfeeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;31m#             # print loss and accuracy (per minibatch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for _ in range(1000):\n",
    "    m2.Train()\n",
    "    m.Train()\n",
    "    m.Test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
